<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Expression to Speech</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-detection"></script>
</head>
<body>
    <h1>Facial Expression to Speech</h1>
    <video id="video" width="640" height="480" autoplay muted></video>
    <p id="expression"></p>

    <script>
        // Load the models
        async function loadModels() {
            return await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);
        }

        async function setupCamera() {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            return new Promise(resolve => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        function speak(text) {
            const synth = window.speechSynthesis;
            const utterance = new SpeechSynthesisUtterance(text);
            synth.speak(utterance);
        }

        async function detectExpressions(video, model) {
            const predictions = await model.estimateFaces({ input: video });
            if (predictions.length > 0) {
                const face = predictions[0];
                // Simple logic to determine expression (you can refine this)
                const landmarks = face.scaledMesh;

                const leftEye = landmarks[159]; // Example point for left eye
                const rightEye = landmarks[386]; // Example point for right eye
                const mouth = landmarks[13]; // Example point for mouth

                const isSmiling = mouth[1] > leftEye[1] && mouth[1] > rightEye[1];

                const expression = isSmiling ? 'smiling' : 'neutral';
                return expression;
            }
            return null;
        }

        async function main() {
            const video = await setupCamera();
            const model = await loadModels();

            video.play();

            setInterval(async () => {
                const expression = await detectExpressions(video, model);
                if (expression) {
                    document.getElementById('expression').textContent = `You are ${expression}`;
                    speak(`You are ${expression}`);
                }
            }, 2000);
        }

        main();
    </script>
</body>
</html>